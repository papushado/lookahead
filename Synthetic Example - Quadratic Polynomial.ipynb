{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import prop\n",
    "import pred\n",
    "import uncert\n",
    "import models\n",
    "from lookahead import Lookahead\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the data hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seed\n",
    "seed = 3\n",
    "\n",
    "# Coefficients of the ground truth polynomial\n",
    "# coeffs[i] denotes the coefficient of x^i th term\n",
    "coeffs = [0.1, 0.5, -0.8]\n",
    "\n",
    "# Number of Training Samples\n",
    "n = 25  \n",
    "\n",
    "# Our input is drawn from the normal distribution \n",
    "# with std = sig and mean = offset\n",
    "sig = 0.5\n",
    "offset = -0.8\n",
    "\n",
    "# std of noise added to the data\n",
    "ns = 0.25\n",
    "\n",
    "# Split ratio for train-test\n",
    "trn_sz = 0.75\n",
    "\n",
    "# Degree of polynomial regressor\n",
    "degree = 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the ground truth function f*\n",
    "\n",
    "f*(x) =  -0.8 x<sup>2</sup> + 0.5 x + 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fstar():\n",
    "    def __init__(self, coeffs = []):\n",
    "        self.coeffs = coeffs\n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "    def predict(self, x):\n",
    "        c = self.coeffs[-1]\n",
    "        for i in range(2, len(self.coeffs) + 1):\n",
    "            c = self.coeffs[-i] + c*x\n",
    "        return c.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 25 , n_trn: 18 , n_tst: 7\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "fstar = Fstar(coeffs)\n",
    "x = np.random.normal(size = (n, 1), scale = sig) + offset\n",
    "y = fstar.predict(x)\n",
    "y += np.random.normal(scale = ns, size = y.shape)\n",
    "\n",
    "n, d = x.shape\n",
    "x_trn, x_tst, y_trn, y_tst = train_test_split(x, y, test_size = 1 - trn_sz, random_state=seed)\n",
    "n_trn, n_tst = (x_trn.shape[0], x_tst.shape[0])\n",
    "print(\"n:\", n, \", n_trn:\", n_trn, \", n_tst:\", n_tst)\n",
    "xs = [x_trn, x_tst, x]\n",
    "ys = [y_trn, y_tst, y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the model hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: [1.]\n"
     ]
    }
   ],
   "source": [
    "# l1/l2 Regularization coefficient\n",
    "alpha = 0.\n",
    "# Lam controls the tradeoff between accuracy and decision improvement\n",
    "lam = 4.\n",
    "\n",
    "\" Hyperparamteres for Lookahead\"\n",
    "# Decision step size\n",
    "eta = 1.25\n",
    "# Number of cycles for training\n",
    "num_cycles = 5\n",
    "# Z-score controls size of confidence intervas\n",
    "z_score = 1.65 # for confiednce intervals (1.28-90%, 1.65=95%)\n",
    "\n",
    "\"\"\" Hyperparameters for Prediction Model\"\"\"\n",
    "# Learning rate\n",
    "lr_f = 0.05\n",
    "# Number of training iterations\n",
    "num_iter_init = 1000\n",
    "num_iter_f = 100\n",
    "num_iter_base = num_iter_init + num_iter_f*num_cycles\n",
    "\n",
    "\"\"\" Hyperparameters for Uncertanity Model\"\"\"\n",
    "#number of bootstrapped models\n",
    "num_gs = 10 \n",
    "# Learning rate\n",
    "lr_g = 0.05\n",
    "# Number of training iterations\n",
    "num_iter_g = 3000 #for training g in cycles\n",
    "\n",
    "\"\"\" Mask\"\"\" \n",
    "# mask[i] is 1 if it can be changed for making decisions\n",
    "mask = np.ones(d)\n",
    "print('mask:', mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to print performance\n",
    "def get_perf(model, xs, ys, eta, mask, uncert=False):\n",
    "    perf = {'mse':[], 'mae':[], 'improve':[], 'imprate':[], 'contain':[], 'size':[]}\n",
    "    perf['mse'].append([model.mse(x_,y_) for x_,y_ in zip(xs,ys)])\n",
    "    perf['mae'].append([model.mae(x_,y_) for x_,y_ in zip(xs,ys)])\n",
    "    perf['improve'].append([model.improve(x_,y_,eta,mask) for x_,y_ in zip(xs,ys)])\n",
    "    perf['imprate'].append([model.improve_rate(x_,y_,eta,mask) for x_,y_ in zip(xs,ys)])\n",
    "    if uncert:\n",
    "        xsp = [model.move_points(x_) for x_ in xs]\n",
    "        perf['contain'].append([model.contain(x_)[0] for x_ in [*xsp, x]])\n",
    "        perf['size'].append([model.contain(x_)[1] for x_ in [*xsp, x]])\n",
    "    perf = {k:np.asarray(v) for k,v in zip(perf.keys(),perf.values())}\n",
    "    return perf\n",
    "    \n",
    "def print_perf(perf, idx=0, uncert=False):\n",
    "    print('\\ttrn\\ttst\\tall')\n",
    "    print(('mse'+'\\t{:.4f}'*3).format(*perf['mse'][idx,:]))\n",
    "    print(('mae'+'\\t{:.4f}'*3).format(*perf['mae'][idx,:]))\n",
    "    print(('imprv'+'\\t{:.4f}'*3).format(*perf['improve'][idx,:]))\n",
    "    print(('imprt'+'\\t{:.4f}'*3).format(*perf['imprate'][idx,:]))\n",
    "    print()\n",
    "    if uncert:\n",
    "        print('\\ttrn\\'\\ttst\\'\\tall')\n",
    "        print(('contn'+'\\t{:.3f}'*3).format(*perf['contain'][idx,:]))\n",
    "        print(('intrsz'+'\\t{:.3f}'*3).format(*perf['size'][idx,:]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the baseline model with no lookahead regluarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline:\n",
      "t: 0\n",
      "[f] mse: 0.0410, la_reg: 0.0000, norm_reg: 0.0000, obj: 0.0410\n",
      "[f] improve*: -0.539\n",
      "\n",
      "\ttrn\ttst\tall\n",
      "mse\t0.0410\t0.1175\t0.0624\n",
      "mae\t0.1473\t0.3236\t0.1966\n",
      "imprv\t-0.5392\t-0.2610\t-0.4613\n",
      "imprt\t0.1667\t0.4286\t0.2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train baseline\n",
    "verbose = True\n",
    "\n",
    "print('training baseline:')\n",
    "f_model = models.polyRegression(1, 1, degree)\n",
    "f_base = pred.PredModel(d, model = f_model, reg_type='none', alpha=alpha, lr=lr_f, num_iter_init=num_iter_base)\n",
    "model_base = Lookahead(f_base, None, None, lam=0., eta=eta, mask=mask, ground_truth_model=fstar)\n",
    "_, _ = model_base.train(x_trn, y_trn, num_cycles=0, random_state=seed, verbose=verbose)\n",
    "\n",
    "perf_base = get_perf(model_base, xs, ys, eta, mask)\n",
    "print_perf(perf_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the lookahead model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lookahead:\n",
      "t: 0\n",
      "[f] mse: 0.0428, la_reg: 0.0000, norm_reg: 0.0000, obj: 0.0428\n",
      "[f] improve*: -0.428\n",
      "\n",
      "t: 1\n",
      "[h] n_eff: 5.58, w_sum: 1.54\n",
      "[u] loss: 0.0089, norm_reg: 0.0000, obj: 0.0089\n",
      "[u] size: 4.853, contain*: 1.000\n",
      "[f] mse: 0.2113, la_reg: 0.0362, norm_reg: 0.0000, obj: 0.3562\n",
      "[f] improve*: 1.344\n",
      "\n",
      "t: 2\n",
      "[h] n_eff: 4.38, w_sum: 4.60\n",
      "[u] loss: 0.0077, norm_reg: 0.0000, obj: 0.0077\n",
      "[u] size: 1.437, contain*: 1.000\n",
      "[f] mse: 0.1630, la_reg: 0.0233, norm_reg: 0.0000, obj: 0.2563\n",
      "[f] improve*: 1.222\n",
      "\n",
      "t: 3\n",
      "[h] n_eff: 4.51, w_sum: 3.64\n",
      "[u] loss: 0.0078, norm_reg: 0.0000, obj: 0.0078\n",
      "[u] size: 1.835, contain*: 1.000\n",
      "[f] mse: 0.1689, la_reg: 0.0232, norm_reg: 0.0000, obj: 0.2619\n",
      "[f] improve*: 1.239\n",
      "\n",
      "t: 4\n",
      "[h] n_eff: 4.49, w_sum: 3.75\n",
      "[u] loss: 0.0078, norm_reg: 0.0000, obj: 0.0078\n",
      "[u] size: 1.784, contain*: 1.000\n",
      "[f] mse: 0.1666, la_reg: 0.0236, norm_reg: 0.0000, obj: 0.2612\n",
      "[f] improve*: 1.233\n",
      "\n",
      "t: 5\n",
      "[h] n_eff: 4.50, w_sum: 3.71\n"
     ]
    }
   ],
   "source": [
    "# train our model\n",
    "verbose = True\n",
    "\n",
    "print('Training lookahead:')\n",
    "f_model = models.polyRegression(1, 1, degree)\n",
    "g_model = models.polyRegression(1, 1, degree)\n",
    "\n",
    "f = pred.PredModel(d, model = f_model, reg_type='none', alpha=0., lr=lr_f, num_iter=num_iter_f, num_iter_init=num_iter_init)\n",
    "u = uncert.Bootstrap(d, model = g_model, alpha=0., num_gs=num_gs, z_score=z_score, lr=lr_g, num_iter=num_iter_g)\n",
    "h = prop.PropModel(random_state=seed)\n",
    "model = Lookahead(f, u, h, lam=lam, eta=eta, mask=mask, ground_truth_model=fstar)\n",
    "_, _ = model.train(x_trn, y_trn, num_cycles=num_cycles, random_state=seed, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the performance of baseline model vs model trained with lookahead regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_base = get_perf(model_base, xs, ys, eta, mask)\n",
    "perf_la = get_perf(model, xs, ys, eta, mask, uncert=True)\n",
    "\n",
    "print('\\nBaseline Model:')\n",
    "print_perf(perf_base)\n",
    "print('Lookahead Model:')\n",
    "print_perf(perf_la, uncert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results\n",
    "The main plot shows the predictions generated by the lookahead model.  The inlay plot shows the performance of the baseline classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plotting\n",
    "def plot_quad(ax, M, x, y, x_plot, y_plot, eta, mask, lw=1, osz=50, olw=1):\n",
    "    x_plot_th = torch.from_numpy(x_plot.astype(np.float32))\n",
    "    ax.plot(x_plot, y_plot, '--', color=\"tab:orange\", linewidth =1.0, label =\"gt\", alpha=0.6)\n",
    "\n",
    "    f_pred = M.f.predict(x_plot)\n",
    "    ax.plot(x_plot, f_pred, label=\"f\", linewidth=lw, alpha=0.6)\n",
    "\n",
    "    if M.u is not None:\n",
    "        u_pred, l_pred = M.u.lu(x_plot_th)\n",
    "        u_pred = u_pred.detach().numpy()\n",
    "        l_pred = l_pred.detach().numpy()\n",
    "        ax.fill_between(x_plot.flatten(), u_pred.flatten(), l_pred.flatten(),  color='g', alpha=0.05, zorder=0)\n",
    "        ax.plot(x_plot.flatten(), u_pred.flatten(), \"tab:green\", linewidth=1.0, alpha=0.5, zorder=0)\n",
    "        ax.plot(x_plot.flatten(), l_pred.flatten(), \"tab:green\", linewidth=1.0, alpha=0.5, zorder=0)\n",
    "\n",
    "    xp = M.move_points(x, eta, mask)\n",
    "    ypstar = M.fstar.predict(xp)\n",
    "    ax.scatter(x, y, color=\"white\", edgecolor=\"tab:blue\", alpha = 1, s=osz, zorder=10, linewidth=olw)\n",
    "    ax.scatter(xp, ypstar, color=\"white\", edgecolor=\"tab:red\", alpha = 1, s=osz, zorder=10, linewidth=olw)\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (6.0, 4.5)\n",
    "x_plot = np.linspace(-3.0, 3.0, 1000)[:, np.newaxis]\n",
    "y_plot = fstar.predict(x_plot)\n",
    "\n",
    "ax = plt.axes()\n",
    "plot_quad(ax, model, x, y, x_plot, y_plot, eta, mask, lw=2)\n",
    "ax.set_xlim([-2.2, 2.2])\n",
    "ax.set_ylim([-4, 1])\n",
    "plt.title(r'$\\eta={}$'.format(eta))\n",
    "\n",
    "axins = inset_axes(ax, width=\"40%\", height=\"40%\", loc=4)\n",
    "plot_quad(axins, model_base, x, y, x_plot, y_plot, eta, mask, osz=10, olw=0.5)\n",
    "axins.set_xlim([-2, 3.3])\n",
    "axins.set_ylim([-7, 1.0])\n",
    "\n",
    "ax.legend([r'$f^*$',r'$f$',r'$g$',r'$(x,y)$',r\"$(x',y')$\"],fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch_holyseas]",
   "language": "python",
   "name": "conda-env-.conda-pytorch_holyseas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
